{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcald\\AppData\\Local\\Temp\\ipykernel_8180\\1309598143.py:35: UserWarning: loadtxt: input contained no data: \"trajectories.txt\"\n",
      "  data = np.loadtxt(filename,encoding=\"utf-16\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Compute the average mutual information divided by time\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m I_c_estimated \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_average_mutual_information\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mtime\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(I_c_estimated)\n",
      "Cell \u001b[1;32mIn[11], line 38\u001b[0m, in \u001b[0;36mcompute_average_mutual_information\u001b[1;34m(filename, sigma, bins)\u001b[0m\n\u001b[0;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(filename,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Determine dimensions: n time steps and total columns = 2*M.\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m n, total_cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     39\u001b[0m M \u001b[38;5;241m=\u001b[39m total_cols \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# ----- Term 1: Constant Gaussian factor -----\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_average_mutual_information(filename, sigma, bins='auto'):\n",
    "    \"\"\"\n",
    "    Compute the average mutual information I_c from trajectory data.\n",
    "    \n",
    "    The data file (filename) is assumed to be a text file containing\n",
    "    an array of shape (n, 2*M) where:\n",
    "      - n ~ 4000 is the number of time steps\n",
    "      - 2*M is the total number of columns with M trajectory pairs:\n",
    "            * Column 0, 2, 4, ... are the X trajectories.\n",
    "            * Column 1, 3, 5, ... are the corresponding Y trajectories.\n",
    "    The formula used is:\n",
    "    \n",
    "        I_c = - n * ln(√(2π)*σ)\n",
    "              - (1/(2σ² * M)) * Σ_{m=1}^{M} Σ_{k=1}^{n} (x_{mk} - y_{mk})²\n",
    "              + Σ_{k=1}^{n} H(P[y_k])\n",
    "              \n",
    "    where H(P[y_k]) is the Shannon entropy (using natural log) of the distribution\n",
    "    of the Y values at time step k.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Name of the file containing the data.\n",
    "    sigma : float\n",
    "        The measurement noise standard deviation.\n",
    "    bins : int or str, optional\n",
    "        Parameter for np.histogram to estimate the density. Default is 'auto'.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    I_c_est : float\n",
    "        The estimated average mutual information (in nats).\n",
    "    \"\"\"\n",
    "    # Load the data; assumes whitespace-separated values.\n",
    "    data = np.loadtxt(filename,encoding=\"utf-16\")\n",
    "    \n",
    "    # Determine dimensions: n time steps and total columns = 2*M.\n",
    "    n, total_cols = data.shape\n",
    "    M = total_cols // 2\n",
    "    \n",
    "    # ----- Term 1: Constant Gaussian factor -----\n",
    "    term1 = - n * math.log(math.sqrt(2 * math.pi) * sigma)\n",
    "    \n",
    "    # ----- Term 2: Sum of squared differences between X and Y -----\n",
    "    sum_sq_diff = 0.0\n",
    "    for m in range(M):\n",
    "        # Extract the m-th X trajectory (column index 2*m)\n",
    "        x_traj = data[:, 2 * m]\n",
    "        # Extract the m-th Y trajectory (column index 2*m + 1)\n",
    "        y_traj = data[:, 2 * m + 1]\n",
    "        # Sum squared differences for this trajectory\n",
    "        sum_sq_diff += np.sum((x_traj - y_traj) ** 2)\n",
    "    term2 = - (1.0 / (2 * sigma**2 * M)) * sum_sq_diff\n",
    "    \n",
    "    # ----- Term 3: Sum over time steps of the entropy of P[y_k] -----\n",
    "    # For each time step, we gather the Y values from all M trajectories.\n",
    "    entropy_sum = 0.0\n",
    "    for k in range(n):\n",
    "        # y_k contains the Y values at time step k from all trajectories.\n",
    "        y_k = data[k, 1::2]  # slice starting at index 1 with step 2\n",
    "        # Estimate the density using a histogram; density=True returns a PDF.\n",
    "        counts, bin_edges = np.histogram(y_k, bins=bins, density=True)\n",
    "        # Get bin widths and approximate the probability mass in each bin.\n",
    "        bin_widths = np.diff(bin_edges)\n",
    "        pmf = counts * bin_widths\n",
    "        # Remove zero probabilities to avoid log(0).\n",
    "        pmf = pmf[pmf > 0]\n",
    "        # Compute Shannon entropy (in nats) for this time step.\n",
    "        H_k = -np.sum(pmf * np.log(pmf))\n",
    "        entropy_sum += H_k\n",
    "    term3 = entropy_sum\n",
    "    \n",
    "    # ----- Combine terms to obtain the estimated mutual information -----\n",
    "    I_c_est = term1 + term2 + term3\n",
    "    return I_c_est\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # File containing the trajectories\n",
    "    filename = \"trajectories.txt\"\n",
    "    \n",
    "    # Given noise sigma is 1/11\n",
    "    sigma = 1.0/0.5\n",
    "    time = 10\n",
    "    \n",
    "    # Compute the average mutual information divided by time\n",
    "    I_c_estimated = compute_average_mutual_information(filename, sigma)/time\n",
    "    print(I_c_estimated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
