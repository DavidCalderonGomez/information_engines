{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcald\\AppData\\Local\\Temp\\ipykernel_9956\\3790898136.py:20: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv('trajectories.txt', header=None, delim_whitespace=True, encoding='utf-16')\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 15.3 MiB for an array with shape (3999, 500) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m     log_prob_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([compute_log_p_x_given_y(j) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M)])  \u001b[38;5;66;03m# P(x | s'_j)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logsumexp(log_prob_x) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(M)\n\u001b[1;32m---> 59\u001b[0m log_p_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mcompute_log_p_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M)])\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# ---------------- Marginal Entropy H(X) ----------------\u001b[39;00m\n\u001b[0;32m     62\u001b[0m H_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(log_p_x)\n",
      "Cell \u001b[1;32mIn[3], line 56\u001b[0m, in \u001b[0;36mcompute_log_p_x\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_log_p_x\u001b[39m(i):\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Compute log P(x_i) using the Monte Carlo marginalization over s \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     log_prob_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mcompute_log_p_x_given_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M)])  \u001b[38;5;66;03m# P(x | s'_j)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logsumexp(log_prob_x) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(M)\n",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m, in \u001b[0;36mcompute_log_p_x_given_y\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m     41\u001b[0m y_i \u001b[38;5;241m=\u001b[39m measurements[:, i]\u001b[38;5;241m.\u001b[39mreshape(T, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Measurement trajectory i (shape: (T, 1))\u001b[39;00m\n\u001b[0;32m     42\u001b[0m diff \u001b[38;5;241m=\u001b[39m y_i \u001b[38;5;241m-\u001b[39m positions  \u001b[38;5;66;03m# Difference matrix (T, M) comparing y_i to all x_j\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m sum_sq_diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mdiff\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Sum over time to get (M,) vector\u001b[39;00m\n\u001b[0;32m     44\u001b[0m log_prob_x_given_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(eq_weights) \u001b[38;5;241m-\u001b[39m sum_sq_diff \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Include P_eq(x0)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(log_prob_x_given_y)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 15.3 MiB for an array with shape (3999, 500) and data type float64"
     ]
    }
   ],
   "source": [
    "# ---------------- Parameters ----------------\n",
    "sigma = 1/11  # Noise standard deviation\n",
    "\n",
    "# ---------------- Data Input ----------------\n",
    "data = pd.read_csv('trajectories.txt', header=None, delim_whitespace=True, encoding='utf-16')\n",
    "\n",
    "# Get the number of time steps (rows) and total columns.\n",
    "T, total_cols = data.shape\n",
    "M = total_cols // 2  # Number of trajectories\n",
    "\n",
    "# Extract positions (true states) and measurements.\n",
    "positions = data.iloc[:, 0::2].values   # True positions (shape: (T, M))\n",
    "measurements = data.iloc[:, 1::2].values  # Corresponding measurements (shape: (T, M))\n",
    "\n",
    "# ---------------- Conditional Entropy H(X | S) ----------------\n",
    "# Compute log P(x | y) for each trajectory pair (i, j), now including normalized equilibrium probability\n",
    "\n",
    "def compute_log_p_x_given_y(i):\n",
    "    \"\"\" Compute log probability log P(x_i | y_i) using Monte Carlo approximation \"\"\"\n",
    "    y_i = measurements[:, i].reshape(T, 1)  # Measurement trajectory i (shape: (T, 1))\n",
    "    diff = y_i - positions  # Difference matrix (T, M) comparing y_i to all x_j\n",
    "    sum_sq_diff = np.sum(diff**2, axis=0)  # Sum over time to get (M,) vector\n",
    "    log_prob_x_given_y = np.log(eq_weights) - sum_sq_diff / (2 * sigma**2)  # Include P_eq(x0)\n",
    "    return np.mean(log_prob_x_given_y)  # Average over M samples\n",
    "\n",
    "log_p_x_given_y = np.array([compute_log_p_x_given_y(i) for i in range(M)])\n",
    "\n",
    "H_X_given_S = -np.mean(log_p_x_given_y)  # Conditional entropy\n",
    "\n",
    "# ---------------- Marginal Probability Estimate P(x) ----------------\n",
    "# Monte Carlo estimate: P(x) â‰ˆ (1/M) sum_j P(x | s'_j)\n",
    "\n",
    "def compute_log_p_x(i):\n",
    "    \"\"\" Compute log P(x_i) using the Monte Carlo marginalization over s \"\"\"\n",
    "    log_prob_x = np.array([compute_log_p_x_given_y(j) for j in range(M)])  # P(x | s'_j)\n",
    "    return logsumexp(log_prob_x) - np.log(M)\n",
    "\n",
    "log_p_x = np.array([compute_log_p_x(i) for i in range(M)])\n",
    "\n",
    "# ---------------- Marginal Entropy H(X) ----------------\n",
    "H_X = -np.mean(log_p_x)\n",
    "\n",
    "# ---------------- Mutual Information Calculation ----------------\n",
    "I_X_S = H_X - H_X_given_S\n",
    "\n",
    "# ---------------- Results ----------------\n",
    "print(f\"Conditional Entropy H(X|S): {H_X_given_S}\")\n",
    "print(f\"Marginal Entropy H(X): {H_X}\")\n",
    "print(f\"Mutual Information I(X;S): {I_X_S}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
